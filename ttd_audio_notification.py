#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ttd_audio_notification.py
--------------------------
Script for processing Two-Tone Detect audio notifications.

Author: Your Name
Version: v2.5.0
Date: 2024-09-24

Description:
This script performs the following tasks:
- Uploads audio files generated by Two-Tone Detect to an FTP server.
- Sends webhook notifications to a Node-RED server upon successful upload.
- Initiates a transcription process for the uploaded audio files.
- Sends Pushover notifications for errors, successes, and maintenance tasks.
- Implements enhanced logging with structured JSON logs, including contextual information.
- Rotates and archives logs based on time and retention policies.
- Monitors performance metrics (CPU and memory usage) and sends alerts if thresholds are exceeded.
- Groups routine task notifications and non-critical errors into consolidated alerts.
- Sends immediate notifications for critical errors to ensure prompt attention.

Enhancements in v2.5.0:
- Implemented grouped notifications for routine tasks and non-critical errors.
- Defined critical error types that trigger immediate Pushover notifications.
- Ensured that notifications are sent even if the script encounters early failures.
- Enhanced error handling to accommodate grouped notifications.

Usage:
Run this script with the required arguments:
    python ttd_audio_notification.py <audio_file> <department>

Example:
    python ttd_audio_notification.py "alert_2024_09_16_14_42_10.mp3" "FireDepartment"

Dependencies:
- Python 3.x
- External libraries: requests, psutil, python-dotenv, pytz

Notes:
- Ensure that the 'config.ini' file is properly configured.
- Sensitive information like FTP credentials and Pushover tokens should be stored securely.
"""

import os
import sys
import logging
import logging.config
import json
import uuid
import requests
import psutil
from subprocess import Popen, PIPE
from ftplib import FTP, error_reply, error_temp, error_perm, error_proto
import configparser
from time import sleep, time
from datetime import datetime
from dotenv import load_dotenv
import shutil
import gzip
import itertools
import signal
from threading import Thread, Lock, Event
import argparse
from enum import Enum
import math
import pytz  # For timezone handling
import re

# -----------------------------------------------------------------------------
# Dependency Management
# -----------------------------------------------------------------------------
# Ensure dependencies are installed via requirements.txt.
# Avoid auto-installing within the script to prevent unexpected behaviors.

# -----------------------------------------------------------------------------
# Script Information
# -----------------------------------------------------------------------------
script_version = "v2.5.0"
script_name = os.path.basename(__file__)
environment = os.getenv('ENVIRONMENT', 'production')

# -----------------------------------------------------------------------------
# Load Environment Variables
# -----------------------------------------------------------------------------
load_dotenv()

# -----------------------------------------------------------------------------
# Configuration
# -----------------------------------------------------------------------------
script_dir = os.path.dirname(os.path.abspath(__file__))
config_path = os.path.join(script_dir, 'config.ini')

config = configparser.ConfigParser()
config.read([config_path])

# -----------------------------------------------------------------------------
# Logging Configuration
# -----------------------------------------------------------------------------
log_dir = os.path.join(script_dir, config['ttd_audio_notification_Logging']['log_dir'])
log_level = config['ttd_audio_notification_Logging']['log_level']
log_to_console = config.getboolean('ttd_audio_notification_Logging', 'log_to_console')
max_logs = int(config['ttd_audio_notification_Logging']['max_logs'])
max_log_days = int(config['ttd_audio_notification_Logging']['max_log_days'])

# Ensure the log directory exists
os.makedirs(log_dir, exist_ok=True)

# Define the log file path
log_file_name = f"audio_notification_{datetime.now().strftime('%Y-%m-%d')}.log"
log_file_path = os.path.join(log_dir, log_file_name)

# Define a unique correlation ID for the script run
correlation_id = str(uuid.uuid4())

# Log Entry ID Counter with thread safety
entry_id_counter = itertools.count()
counter_lock = Lock()

# Enumerations for error types
class ErrorType(Enum):
    FTPConnectionError = "FTPConnectionError"
    FileUploadError = "FileUploadError"
    WebhookError = "WebhookError"
    HighMemoryUsage = "HighMemoryUsage"
    HighCPUUsage = "HighCPUUsage"
    UnexpectedError = "UnexpectedError"
    FileNotFoundError = "FileNotFoundError"
    ConfigurationError = "ConfigurationError"
    CriticalSystemError = "CriticalSystemError"  # New Critical Error Type

# Custom JSON Formatter
class JsonFormatter(logging.Formatter):
    def format(self, record):
        # Generate a unique entry ID in a thread-safe manner
        with counter_lock:
            entry_id = next(entry_id_counter)
        
        # Build the log record as a dictionary
        log_record = {
            'timestamp': self.formatTime(record, self.datefmt),
            'level': record.levelname,
            'message': record.getMessage(),
            'module': record.module,
            'function': record.funcName,
            'line_no': record.lineno,
            'correlation_id': correlation_id,
            'entry_id': entry_id,
            'environment': environment,
            'script_version': script_version,
        }
        # Include any extra context variables
        if hasattr(record, 'file_name'):
            log_record['file_name'] = record.file_name
        if hasattr(record, 'department'):
            log_record['department'] = record.department
        if hasattr(record, 'memory_usage'):
            log_record['memory_usage'] = record.memory_usage
        if hasattr(record, 'cpu_usage'):
            log_record['cpu_usage'] = record.cpu_usage
        if hasattr(record, 'attempt'):
            log_record['attempt'] = record.attempt
        if hasattr(record, 'payload'):
            log_record['payload'] = record.payload
        if hasattr(record, 'execution_time'):
            log_record['execution_time'] = record.execution_time
        if hasattr(record, 'status_code'):
            log_record['status_code'] = record.status_code
        if hasattr(record, 'response_text'):
            log_record['response_text'] = record.response_text
        if hasattr(record, 'retry_delay'):
            log_record['retry_delay'] = record.retry_delay
        if record.exc_info:
            log_record['exception'] = self.formatException(record.exc_info)
        return json.dumps(log_record)

# Custom Handler with Compression and Error Handling
from logging.handlers import TimedRotatingFileHandler

class GzTimedRotatingFileHandler(TimedRotatingFileHandler):
    def doRollover(self):
        try:
            super().doRollover()
            if self.backupCount > 0:
                for s in self.getFilesToDelete():
                    if os.path.exists(s):
                        with open(s, 'rb') as f_in, gzip.open(f"{s}.gz", 'wb') as f_out:
                            shutil.copyfileobj(f_in, f_out)
                        os.remove(s)
                        self.logger.info(f"Compressed and archived log file: {os.path.basename(s)}")
        except Exception as e:
            self.logger.error("Error during log rollover and compression", exc_info=True)

# Configure logging
logging_config = {
    'version': 1,
    'disable_existing_loggers': False,  # Ensure existing loggers are not disabled
    'formatters': {
        'json': {
            '()': JsonFormatter,
        },
    },
    'handlers': {
        'file': {
            'class': '__main__.GzTimedRotatingFileHandler',
            'formatter': 'json',
            'filename': log_file_path,
            'when': 'midnight',
            'backupCount': max_logs,
        },
        'console': {
            'class': 'logging.StreamHandler',
            'formatter': 'json',
        },
    },
    'root': {
        'level': log_level.upper(),
        'handlers': ['file', 'console'] if log_to_console else ['file'],
    },
    # Configure loggers for third-party modules
    'loggers': {
        'requests': {
            'level': log_level.upper(),
            'handlers': [],
            'propagate': True,
        },
        'urllib3': {
            'level': log_level.upper(),
            'handlers': [],
            'propagate': True,
        },
    },
}

logging.config.dictConfig(logging_config)
logger = logging.getLogger(__name__)

logger.info("Logging initialized.")

# -----------------------------------------------------------------------------
# Notification Tracking Lists
# -----------------------------------------------------------------------------
task_list = []     # List to store routine task messages
error_list = []    # List to store non-critical error messages

# -----------------------------------------------------------------------------
# Error Notification Timestamps for Throttling
# -----------------------------------------------------------------------------
error_notification_timestamps = {}
notification_lock = Lock()

# -----------------------------------------------------------------------------
# Function: get_current_timestamp
# -----------------------------------------------------------------------------
def get_current_timestamp():
    """
    Returns the current timestamp formatted as 'September 24th, 2024 23:30:10 CDT',
    considering daylight saving time.
    """
    tz = pytz.timezone('America/Chicago')  # Adjust to your timezone
    current_time = datetime.now(tz)
    day = current_time.day
    # Determine the ordinal suffix
    if 10 <= day % 100 <= 20:
        suffix = 'th'
    else:
        suffix = {1: 'st', 2: 'nd', 3: 'rd'}.get(day % 10, 'th')
    formatted_time = current_time.strftime(f"%B {day}{suffix}, %Y %H:%M:%S %Z")
    return formatted_time

# -----------------------------------------------------------------------------
# Function: send_pushover_notification
# -----------------------------------------------------------------------------
def send_pushover_notification(message, title="Notification", priority=0, sound=None, error_type=None, immediate=False):
    """
    Sends a Pushover notification.
    
    Parameters:
    - message (str): The notification message.
    - title (str): The notification title.
    - priority (int): Pushover priority (-2 to 2).
    - sound (str): Notification sound.
    - error_type (ErrorType): The type of error (if applicable).
    - immediate (bool): If True, send the notification immediately without grouping.
    """
    try:
        # Retrieve cooldown_period from config or use default
        cooldown_period = config['ttd_audio_notification_Pushover'].getint('cooldown_period', fallback=300)  # seconds
        now = time()
        
        if error_type and not immediate:
            with notification_lock:
                last_sent = error_notification_timestamps.get(error_type.value, 0)
                if now - last_sent < cooldown_period:
                    logger.info(f"Notification for {error_type.value} suppressed to avoid overload.")
                    return
                else:
                    error_notification_timestamps[error_type.value] = now

        full_title = f"{script_name}: {title}"

        payload = {
            'token': config['Validated']['pushover_token'],
            'user': config['Validated']['pushover_user'],
            'message': message,
            'title': full_title,
            'priority': priority,
            'sound': sound or config['ttd_audio_notification_Pushover']['sound']
        }

        if priority == 2:
            # Emergency priority requires 'retry' and 'expire' parameters
            payload['retry'] = int(config['Validated']['retry'])
            payload['expire'] = int(config['Validated']['expire'])

        logger.debug(f"Attempting to send Pushover notification: {title} - {message}")
        response = requests.post("https://api.pushover.net/1/messages.json", data=payload)
        response.raise_for_status()
        logger.info("Pushover notification sent successfully", extra={'status_code': response.status_code, 'response_text': response.text})
    except requests.exceptions.HTTPError as http_err:
        logger.error(f"Pushover HTTP error occurred: {http_err}", exc_info=True)
    except requests.exceptions.RequestException as req_err:
        logger.error(f"Pushover request exception: {req_err}", exc_info=True)
    except Exception as e:
        logger.error("Failed to send Pushover notification", exc_info=True)

# -----------------------------------------------------------------------------
# Function: cleanup_logs
# -----------------------------------------------------------------------------
def cleanup_logs():
    task_list.append("Starting log cleanup.")
    logger.info("Starting log cleanup.", extra={'file_name': 'N/A', 'department': 'N/A'})
    now = datetime.now().timestamp()
    logs = []

    # Gather all logs and their ages
    for filename in os.listdir(log_dir):
        file_path = os.path.join(log_dir, filename)
        if os.path.isfile(file_path) and filename.endswith('.log'):
            file_age = now - os.path.getmtime(file_path)
            logs.append((file_path, file_age))

    # Sort logs by age (oldest first)
    logs.sort(key=lambda x: x[1])

    # Get the current log file path to avoid deletion
    current_log_file = log_file_path

    # Archive logs based on age
    archived_files_count = 0
    for file_path, file_age in logs:
        if file_path == current_log_file:
            continue
        if file_age > max_log_days * 86400:
            # Move the file to an archive directory atomically
            archive_dir = os.path.join(log_dir, 'archive')
            os.makedirs(archive_dir, exist_ok=True)
            destination = os.path.join(archive_dir, os.path.basename(file_path))
            try:
                shutil.move(file_path, destination)
                task_list.append(f"Archived old log file: {os.path.basename(file_path)}")
                logger.info(f"Archived old log file: {os.path.basename(file_path)}")
                archived_files_count += 1
            except Exception as e:
                error_message = f"Failed to archive log file {file_path}"
                error_list.append(error_message)
                logger.error(error_message, exc_info=True)

    # Re-evaluate logs after age-based cleanup
    logs = [(fp, fa) for fp, fa in logs if os.path.exists(fp)]

    # If number of logs exceeds max_logs, archive the oldest ones
    if len(logs) > max_logs:
        logs_to_archive = len(logs) - max_logs
        for i in range(logs_to_archive):
            if logs[i][0] == current_log_file:
                continue
            archive_dir = os.path.join(log_dir, 'archive')
            os.makedirs(archive_dir, exist_ok=True)
            destination = os.path.join(archive_dir, os.path.basename(logs[i][0]))
            try:
                shutil.move(logs[i][0], destination)
                task_list.append(f"Archived excess log file: {os.path.basename(logs[i][0])}")
                logger.info(f"Archived excess log file: {os.path.basename(logs[i][0])}")
                archived_files_count += 1
            except Exception as e:
                error_message = f"Failed to archive log file {logs[i][0]}"
                error_list.append(error_message)
                logger.error(error_message, exc_info=True)

    if archived_files_count == 0:
        task_list.append("No old or excess log files were found for archiving.")
        logger.info("No old or excess log files were found for archiving.")
    else:
        task_list.append(f"Archived {archived_files_count} old or excess log file(s).")
        logger.info(f"Archived {archived_files_count} old or excess log file(s).")

    task_list.append("Log cleanup completed.")
    logger.info("Log cleanup completed.", extra={'file_name': 'N/A', 'department': 'N/A'})

# -----------------------------------------------------------------------------
# Custom Exception Definitions
# -----------------------------------------------------------------------------
class FTPConnectionError(Exception):
    """Raised when FTP connection fails."""
    pass

class FileUploadError(Exception):
    """Raised when file upload fails."""
    pass

class WebhookError(Exception):
    """Raised when webhook sending fails."""
    pass

class CriticalSystemError(Exception):
    """Raised for critical system failures that require immediate attention."""
    pass

# -----------------------------------------------------------------------------
# Function: log_and_validate_config
# -----------------------------------------------------------------------------
def log_and_validate_config():
    try:
        logger.info("Starting configuration validation...")

        # Pushover settings
        pushover_token = os.getenv('PUSHOVER_TOKEN') or config['ttd_audio_notification_Pushover']['pushover_token']
        pushover_user = os.getenv('PUSHOVER_USER') or config['ttd_audio_notification_Pushover']['pushover_user']
        priority = config['ttd_audio_notification_Pushover'].getint('priority')
        retry = config['ttd_audio_notification_Pushover'].getint('retry')
        expire = config['ttd_audio_notification_Pushover'].getint('expire')
        sound = config['ttd_audio_notification_Pushover']['sound']
        cooldown_period = config['ttd_audio_notification_Pushover'].getint('cooldown_period', fallback=300)

        # Log non-sensitive Pushover settings
        logger.debug(f"Pushover User: {pushover_user}")

        # Validate Pushover settings
        if not pushover_token or not pushover_user:
            raise ValueError("Pushover configuration missing or incomplete in .env or config.ini")

        # Validate priority, retry, expire
        if priority not in [-2, -1, 0, 1, 2]:
            raise ValueError("Pushover priority must be between -2 and 2.")

        if retry <= 0 or expire <= 0:
            raise ValueError("Pushover retry and expire must be positive integers.")

        # Webhook settings
        if config.has_option('ttd_audio_notification_Webhook', 'ttd_audio_received_url'):
            webhook_url = config['ttd_audio_notification_Webhook']['ttd_audio_received_url']
            if not re.match(r'^https?://', webhook_url):
                raise ValueError("Webhook URL must start with http:// or https://")
        else:
            raise ValueError("Webhook URL is missing in config.ini")

        # Retry delay for webhook
        retry_delay = config['ttd_audio_notification_Webhook'].getint('retry_delay', fallback=5)
        if retry_delay <= 0:
            raise ValueError("Retry delay must be a positive integer.")

        # FTP settings
        ftp_server = os.getenv('FTP_SERVER') or config['ttd_audio_notification_ftp']['ftp_server']
        ftp_port = os.getenv('FTP_PORT') or config['ttd_audio_notification_ftp']['ftp_port']
        ftp_user = os.getenv('FTP_USER') or config['ttd_audio_notification_ftp']['ftp_user']
        ftp_pass = os.getenv('FTP_PASS') or config['ttd_audio_notification_ftp']['ftp_pass']

        # Log non-sensitive FTP settings
        logger.debug(f"FTP Server: {ftp_server}, FTP Port: {ftp_port}, FTP User: {ftp_user}")

        # Validate FTP settings
        if not ftp_server or not ftp_port or not ftp_user or not ftp_pass:
            raise ValueError("FTP configuration missing or incomplete in .env or config.ini")

        if not re.match(r'^\d+$', ftp_port):
            raise ValueError("FTP port must be a number.")

        # Base path for audio files
        base_path = config['ttd_audio_notification_Path']['base_path']
        logger.debug(f"Base Path: {base_path}")

        if not base_path or not os.path.isdir(base_path):
            raise ValueError("Base path for audio files is missing or invalid in config.ini")

        # Webhook base audio URL
        if config.has_option('ttd_audio_notification_Webhook', 'base_audio_url'):
            base_audio_url = config['ttd_audio_notification_Webhook']['base_audio_url']
            if not re.match(r'^https?://', base_audio_url):
                raise ValueError("Base audio URL must start with http:// or https://")
        else:
            raise ValueError("Base audio URL is missing in config.ini")

        # Store validated values in 'Validated' section
        config['Validated'] = {
            'ftp_server': ftp_server,
            'ftp_port': ftp_port,
            'ftp_user': ftp_user,
            'ftp_pass': ftp_pass,
            'base_path': base_path,
            'pushover_token': pushover_token,
            'pushover_user': pushover_user,
            'priority': str(priority),
            'retry': str(retry),
            'expire': str(expire),
            'sound': sound,
            'webhook_url': webhook_url,
            'base_audio_url': base_audio_url,
            'retry_delay': str(retry_delay),
            'cooldown_period': str(cooldown_period)
        }

        logger.debug("Configuration validation completed successfully.")
        logger.debug("Validated Configuration: ftp_server, ftp_port, ftp_user, ftp_pass, base_path, pushover_token, pushover_user, priority, retry, expire, sound, webhook_url, base_audio_url, retry_delay, cooldown_period")

    except Exception as e:
        logger.error("Configuration validation failed", exc_info=True)
        # Send immediate notification if configuration fails
        send_pushover_notification(
            str(e),
            title="Configuration Error",
            priority=1,
            sound='bugle',
            error_type=ErrorType.ConfigurationError,
            immediate=True  # Send immediately
        )
        raise

# -----------------------------------------------------------------------------
# Function: connect_to_ftp
# -----------------------------------------------------------------------------
def connect_to_ftp():
    try:
        logger.debug("Connecting to FTP server")
        ftp = FTP()
        ftp.connect(config['Validated']['ftp_server'], int(config['Validated']['ftp_port']), timeout=30)
        ftp.login(config['Validated']['ftp_user'], config['Validated']['ftp_pass'])
        logger.info("Connected to FTP server", extra={'ftp_server': config['Validated']['ftp_server']})
        return ftp
    except (error_reply, error_temp, error_perm, error_proto) as ftp_exc:
        logger.error("FTP connection error", exc_info=True)
        raise FTPConnectionError(f"FTP error: {ftp_exc}")

def connect_to_ftp_with_retries(max_retries=3, backoff_factor=2):
    attempt = 0
    while attempt < max_retries:
        try:
            return connect_to_ftp()
        except FTPConnectionError as e:
            wait_time = backoff_factor ** attempt
            logger.warning(f"FTP connection attempt {attempt + 1} failed. Retrying in {wait_time} seconds...")
            sleep(wait_time)
            attempt += 1
    # After all retries have failed, send immediate critical notification
    message = (
        f"FTPConnectionError at {get_current_timestamp()}: Failed to connect after {max_retries} attempts.\n"
        "Possible causes: FTP server down, network issues.\n"
        "Action: Check FTP server status and network connectivity."
    )
    logger.error("Failed to connect to FTP server after all retries.")
    send_pushover_notification(
        message,
        title="FTP Connection Critical Error",
        priority=2,  # Emergency priority
        sound='siren',
        error_type=ErrorType.FTPConnectionError,
        immediate=True  # Send immediately
    )
    raise FTPConnectionError(f"Failed to connect to FTP after {max_retries} attempts.")

# -----------------------------------------------------------------------------
# Function: store_file
# -----------------------------------------------------------------------------
def store_file(ftp, local_file, department):
    try:
        file_name = os.path.basename(local_file)
        with open(local_file, 'rb') as f:
            logger.debug("Uploading file", extra={'file_name': file_name})
            ftp.storbinary(f'STOR {file_name}', f)
            logger.info("Uploaded file to FTP server", extra={'file_name': file_name})
            task_list.append(f"Uploaded file to FTP server: {file_name}")
            # Send webhook asynchronously
            webhook_thread = Thread(target=send_webhook, args=(file_name, department), daemon=True)
            webhook_thread.start()
    except Exception as e:
        file_name = os.path.basename(local_file)
        error_message = f"Failed to upload to FTP server: {file_name}"
        error_list.append(error_message)
        logger.error(error_message, exc_info=True)
        # Check if it's a critical error
        if isinstance(e, FTPConnectionError):
            send_pushover_notification(
                f"Critical: {error_message}",
                title="FTP Upload Critical Error",
                priority=2,
                sound='siren',
                error_type=ErrorType.CriticalSystemError,
                immediate=True  # Send immediately
            )
        else:
            send_pushover_notification(
                f"Error: {error_message}",
                title="File Upload Error",
                priority=1,
                sound='alien',
                error_type=ErrorType.FileUploadError
            )
        raise FileUploadError(f"Failed to upload to FTP server: {e}")

# -----------------------------------------------------------------------------
# Function: upload_to_ftp
# -----------------------------------------------------------------------------
def upload_to_ftp(local_file, department):
    """Uploads a file to the FTP server and handles FTP-specific errors."""
    try:
        ftp = connect_to_ftp_with_retries()
        if ftp:
            try:
                store_file(ftp, local_file, department)
            finally:
                ftp.quit()
                logger.info("FTP connection closed")
    except FTPConnectionError as ftp_error:
        # Already handled in connect_to_ftp_with_retries
        raise
    except FileUploadError as file_error:
        message = (
            f"FileUploadError at {get_current_timestamp()}: {file_error}\n"
            "Possible causes: File permissions, network issues.\n"
            "Action: Verify file access and network connectivity."
        )
        logger.error("FileUploadError occurred", exc_info=True)
        send_pushover_notification(
            message,
            title="File Upload Error",
            priority=1,
            sound='alien',
            error_type=ErrorType.FileUploadError
        )
        raise file_error

# -----------------------------------------------------------------------------
# Function: run_transcription_script
# -----------------------------------------------------------------------------
def run_transcription_script(mp3_file, department):
    try:
        transcription_script = os.path.join(script_dir, 'ttd_transcribed.py')
        process = Popen([sys.executable, transcription_script, mp3_file, department], stdout=PIPE, stderr=PIPE)
        logger.info("Started transcription script", extra={'file_name': mp3_file, 'pid': process.pid})
        task_list.append(f"Started transcription script for: {os.path.basename(mp3_file)}")
        
        # Start a thread to monitor the process
        monitor_thread = Thread(target=monitor_transcription_process, args=(process, mp3_file), daemon=True)
        monitor_thread.start()
    except Exception as e:
        file_name = os.path.basename(mp3_file)
        error_message = f"Failed to start transcription script for {file_name}"
        error_list.append(error_message)
        logger.error(error_message, exc_info=True)
        send_pushover_notification(
            f"Critical: {error_message}.",
            title="Transcription Script Critical Error",
            priority=2,
            sound='bugle',
            error_type=ErrorType.CriticalSystemError,
            immediate=True  # Send immediately
        )
        raise CriticalSystemError(f"Failed to start transcription script: {e}")

def monitor_transcription_process(process, mp3_file):
    try:
        stdout, stderr = process.communicate()
        if process.returncode != 0:
            error_message = f"Transcription script failed for {mp3_file}. Error: {stderr.decode().strip()}"
            error_list.append(error_message)
            logger.error("Transcription script failed", extra={'file_name': mp3_file, 'return_code': process.returncode, 'stderr': stderr.decode().strip()})
            send_pushover_notification(
                f"Error: {error_message}",
                title="Transcription Error",
                priority=1,
                sound='alien',
                error_type=ErrorType.UnexpectedError
            )
        else:
            success_message = f"Transcription script completed successfully for {mp3_file}. Output: {stdout.decode().strip()}"
            task_list.append(success_message)
            logger.info("Transcription script completed successfully", extra={'file_name': mp3_file, 'stdout': stdout.decode().strip()})
    except Exception as e:
        file_name = os.path.basename(mp3_file)
        error_message = f"Error while monitoring transcription script for {file_name}."
        error_list.append(error_message)
        logger.error("Error while monitoring transcription script", exc_info=True, extra={'file_name': mp3_file})
        send_pushover_notification(
            f"Error: {error_message}",
            title="Transcription Monitoring Error",
            priority=1,
            sound='alien',
            error_type=ErrorType.UnexpectedError
        )

# -----------------------------------------------------------------------------
# Function: send_webhook
# -----------------------------------------------------------------------------
def send_webhook(file_name, topic, retries=3):
    """Sends a webhook notification to the Node-RED server and handles webhook-specific errors."""
    try:
        if not config.has_section('ttd_audio_notification_Webhook'):
            raise KeyError("Webhook configuration missing")

        file_name = os.path.basename(file_name)
        base_audio_url = config['Validated']['base_audio_url']
        file_url = f"{base_audio_url}{file_name}"

        payload = {
            "payload": {
                "message": file_url,
                "title": f"{topic} Audio Uploaded",
                "topic": topic
            }
        }

        attempt = 0
        retry_delay = int(config['Validated']['retry_delay'])
        timeout_seconds = int(config['ttd_audio_notification_Webhook']['timeout_seconds'])

        while attempt < retries:
            try:
                logger.debug("Sending webhook", extra={'attempt': attempt + 1, 'payload': payload})
                response = requests.post(config['Validated']['webhook_url'], json=payload, timeout=timeout_seconds)
                response.raise_for_status()
                logger.info("Webhook sent successfully", extra={'status_code': response.status_code, 'response_text': response.text, 'payload': payload})
                return True
            except requests.exceptions.RequestException as e:
                logger.warning("Webhook attempt failed", exc_info=True, extra={'attempt': attempt + 1})
                attempt += 1
                if attempt < retries:
                    backoff_time = retry_delay * math.pow(2, attempt - 1)  # Exponential backoff
                    logger.info(f"Retrying webhook in {backoff_time} seconds", extra={'retry_delay': backoff_time})
                    sleep(backoff_time)

        # After all retries have failed
        message = (
            f"WebhookError at {get_current_timestamp()}: Failed after {retries} attempts.\n"
            "Possible causes: Node-RED server down, network issues.\n"
            "Action: Check Node-RED server status and verify the webhook URL."
        )
        logger.error("Webhook failed after all retries")
        send_pushover_notification(
            message,
            title="Webhook Error",
            priority=1,
            sound='tugboat',
            error_type=ErrorType.WebhookError
        )
        raise WebhookError(f"Webhook failed after {retries} attempts.")

    except Exception as e:
        logger.error("Webhook error occurred", exc_info=True)
        # Append to error_list if not already handled
        error_message = f"Webhook error: {e}"
        error_list.append(error_message)
        send_pushover_notification(
            f"Error: {error_message}",
            title="Webhook Error",
            priority=1,
            sound='alien',
            error_type=ErrorType.WebhookError
        )
        raise

# -----------------------------------------------------------------------------
# Function: performance_monitor
# -----------------------------------------------------------------------------
def performance_monitor(stop_event):
    """Logs CPU and memory usage periodically."""
    memory_threshold = config['ttd_audio_notification_Performance'].getint('memory_threshold')
    cpu_threshold = config['ttd_audio_notification_Performance'].getint('cpu_threshold')
    interval = config['ttd_audio_notification_Performance'].getint('monitor_interval')  # in seconds

    while not stop_event.is_set():
        try:
            memory_usage = psutil.virtual_memory().percent
            cpu_usage = psutil.cpu_percent(interval=1)
            task_list.append(f"Performance metrics - Memory Usage: {memory_usage}%, CPU Usage: {cpu_usage}%")
            logger.info("Performance metrics", extra={'memory_usage': memory_usage, 'cpu_usage': cpu_usage})

            # Send notifications if usage exceeds thresholds
            if memory_usage > memory_threshold:
                send_pushover_notification(
                    f"High Memory Usage: {memory_usage}%",
                    title="Resource Alert",
                    priority=1,
                    sound='gamelan',
                    error_type=ErrorType.HighMemoryUsage
                )
            if cpu_usage > cpu_threshold:
                send_pushover_notification(
                    f"High CPU Usage: {cpu_usage}%",
                    title="Resource Alert",
                    priority=1,
                    sound='gamelan',
                    error_type=ErrorType.HighCPUUsage
                )
        except Exception as e:
            error_message = "Error in performance monitoring."
            error_list.append(error_message)
            logger.error(error_message, exc_info=True)
            send_pushover_notification(
                f"Error: {error_message}",
                title="Performance Monitoring Error",
                priority=1,
                sound='alien',
                error_type=ErrorType.UnexpectedError
            )
        sleep(interval)

# -----------------------------------------------------------------------------
# Function: parse_arguments
# -----------------------------------------------------------------------------
def parse_arguments():
    parser = argparse.ArgumentParser(description='Process TTD audio notifications.')
    parser.add_argument('audio_file', type=str, help='Name of the audio file.')
    parser.add_argument('department', type=str, help='Name of the department.')
    return parser.parse_args()

# -----------------------------------------------------------------------------
# Graceful Shutdown Handler
# -----------------------------------------------------------------------------
def shutdown_handler(signum, frame):
    logger.info(f"Received shutdown signal ({signum}). Shutting down gracefully...")
    global stop_event
    stop_event.set()

# -----------------------------------------------------------------------------
# Function: send_grouped_notifications
# -----------------------------------------------------------------------------
def send_grouped_notifications():
    """
    Sends grouped Pushover notifications for tasks and non-critical errors.
    """
    if task_list:
        # Extract relevant details for the task summary
        processing_info = ""
        transcription_info = ""
        performance_info = ""
        ftp_upload_info = ""
        log_cleanup_info = ""

        for task in task_list:
            if task.startswith("Processing file:"):
                processing_info = task.replace("Processing file:", "").strip()
            elif task.startswith("Started transcription script for:"):
                transcription_info = task.replace("Started transcription script for:", "").strip()
            elif task.startswith("Performance metrics -"):
                performance_info = task.replace("Performance metrics -", "").strip()
            elif task.startswith("Uploaded file to FTP server:"):
                ftp_upload_info = task.replace("Uploaded file to FTP server:", "").strip()
            elif task.startswith("Archived old log file:") or task.startswith("Archived excess log file:") or task.startswith("No old") or task.startswith("Log cleanup completed."):
                log_cleanup_info = task.strip()

        # Get the current timestamp
        timestamp = get_current_timestamp()

        # Extract department from processing_info
        # processing_info is expected to be "Raymond_2024_09_24_01_26_52.mp3 in department: Raymond"
        match = re.search(r'in department:\s*(\w+)', processing_info)
        department = match.group(1) if match else "Unknown"

        # Build the detailed message
        detailed_message = f"""Task Summary for: {os.path.basename(processing_info).split(' in ')[0]}
- Timestamp: {timestamp}
- Department: {department}
- Transcription: Started
- Performance Metrics: {performance_info}
- FTP Upload: Success (File: {ftp_upload_info})
- Log Cleanup: {log_cleanup_info}
"""

        # Send the grouped Pushover notification
        send_pushover_notification(
            message=detailed_message.strip(),
            title="Task Summary",
            priority=-1
        )
    
    if error_list:
        error_summary = "\n".join(error_list)
        send_pushover_notification(
            error_summary,
            title="Error Summary",
            priority=1
        )

# -----------------------------------------------------------------------------
# Main Execution
# -----------------------------------------------------------------------------
def main():
    global stop_event
    logger.debug("Starting script execution")
    start_time = time()

    # Initialize stop_event for graceful shutdown
    stop_event = Event()
    signal.signal(signal.SIGINT, shutdown_handler)
    signal.signal(signal.SIGTERM, shutdown_handler)

    # Start performance monitoring thread
    perf_thread = Thread(target=performance_monitor, args=(stop_event,), daemon=True)
    perf_thread.start()

    try:
        log_and_validate_config()

        args = parse_arguments()
        mp3_file = os.path.join(config['Validated']['base_path'], args.audio_file)
        department = args.department

        if not os.path.isfile(mp3_file):
            raise FileNotFoundError(f"Audio file '{mp3_file}' does not exist.")

        logger.info("Processing file", extra={'file_name': mp3_file, 'department': department})
        task_list.append(f"Processing file: {os.path.basename(mp3_file)} in department: {department}")

        # Run the transcription script asynchronously
        run_transcription_script(mp3_file, department)

        # Upload to FTP
        upload_to_ftp(mp3_file, department)

    except FileNotFoundError as fnf_error:
        logger.error("File not found error", exc_info=True)
        send_pushover_notification(
            str(fnf_error),
            title="File Not Found",
            priority=1,
            sound='bugle',
            error_type=ErrorType.FileNotFoundError,
            immediate=True  # Send immediately
        )
        sys.exit(2)
    except ValueError as ve:
        logger.error("Value error", exc_info=True)
        send_pushover_notification(
            str(ve),
            title="Configuration Error",
            priority=1,
            sound='bugle',
            error_type=ErrorType.ConfigurationError,
            immediate=True  # Send immediately
        )
        sys.exit(3)
    except CriticalSystemError as cse:
        logger.error("Critical system error occurred", exc_info=True)
        # Critical errors are already notified immediately
        sys.exit(1)
    except Exception as e:
        logger.error("An unexpected error occurred in main execution", exc_info=True)
        message = f"An unexpected error occurred at {get_current_timestamp()}: {e}\nAction: Check logs for details."
        send_pushover_notification(
            message,
            title="Unexpected Error",
            priority=1,
            sound='falling',
            error_type=ErrorType.UnexpectedError,
            immediate=True  # Send immediately
        )
        sys.exit(1)
    finally:
        # Perform log cleanup before sending notifications
        cleanup_logs()
        # Send grouped notifications for tasks and non-critical errors
        send_grouped_notifications()
        execution_time = time() - start_time
        logger.info("Script completed", extra={'execution_time': execution_time})
        logger.debug("Exiting script")
        if stop_event and not stop_event.is_set():
            stop_event.set()
        sys.exit(0)

if __name__ == "__main__":
    main()
