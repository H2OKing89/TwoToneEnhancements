#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ttd_audio_notification.py
-------------------------
Script for processing Two-Tone Detect audio notifications.

Author: Your Name
Version: v2.4.1
Date: 2024-09-17

Description:
This script performs the following tasks:
- Uploads audio files generated by Two-Tone Detect to an FTP server.
- Sends webhook notifications to a Node-RED server upon successful upload.
- Initiates a transcription process for the uploaded audio files.
- Sends Pushover notifications for errors, successes, and maintenance tasks.
- Implements enhanced logging with structured JSON logs, including contextual information.
- Rotates and archives logs based on time and retention policies.
- Monitors performance metrics (CPU and memory usage) and sends alerts if thresholds are exceeded.

Enhancements in v2.4.1:
- Fixed function ordering to prevent NameError.
- Ensured all functions are defined before they are called.

Usage:
Run this script with the required arguments:
    python ttd_audio_notification.py <audio_file> <department>

Example:
    python ttd_audio_notification.py "alert_2024_09_16_14_42_10.mp3" "FireDepartment"

Dependencies:
- Python 3.x
- External libraries: requests, psutil, python-dotenv

Notes:
- Ensure that the 'config.ini' file is properly configured.
- Sensitive information like FTP credentials and Pushover tokens should be stored securely.

"""

import os
import sys
import logging
import logging.config
import json
import uuid
import requests
import psutil
from subprocess import Popen
from ftplib import FTP, error_perm, error_temp
import configparser
from time import sleep, time
from datetime import datetime
from dotenv import load_dotenv
import shutil
import gzip
import itertools
from threading import Thread
import queue

# -----------------------------------------------------------------------------
# Script Information
# -----------------------------------------------------------------------------
script_version = "v2.4.1"
script_name = os.path.basename(__file__)
environment = os.getenv('ENVIRONMENT', 'production')

# -----------------------------------------------------------------------------
# Load Environment Variables
# -----------------------------------------------------------------------------
load_dotenv()

# -----------------------------------------------------------------------------
# Configuration
# -----------------------------------------------------------------------------
script_dir = os.path.dirname(os.path.abspath(__file__))
config_path = os.path.join(script_dir, 'config.ini')

config = configparser.ConfigParser()
config.read([config_path])

# -----------------------------------------------------------------------------
# Logging Configuration
# -----------------------------------------------------------------------------
log_dir = os.path.join(script_dir, config['ttd_audio_notification_Logging']['log_dir'])
log_level = config['ttd_audio_notification_Logging']['log_level']
log_to_console = config.getboolean('ttd_audio_notification_Logging', 'log_to_console')
max_logs = int(config['ttd_audio_notification_Logging']['max_logs'])
max_log_days = int(config['ttd_audio_notification_Logging']['max_log_days'])

# Ensure the log directory exists
os.makedirs(log_dir, exist_ok=True)

# Define the log file path
log_file_name = f"audio_notification_{datetime.now().strftime('%Y-%m-%d')}.log"
log_file_path = os.path.join(log_dir, log_file_name)

# Define a unique correlation ID for the script run
correlation_id = str(uuid.uuid4())

# Log Entry ID Counter
entry_id_counter = itertools.count()

# Custom JSON Formatter
class JsonFormatter(logging.Formatter):
    def format(self, record):
        # Generate a unique entry ID
        record.entry_id = next(entry_id_counter)

        # Build the log record as a dictionary
        log_record = {
            'timestamp': self.formatTime(record, self.datefmt),
            'level': record.levelname,
            'message': record.getMessage(),
            'module': record.module,
            'function': record.funcName,
            'line_no': record.lineno,
            'correlation_id': correlation_id,
            'entry_id': record.entry_id,
            'environment': environment,
            'script_version': script_version,
        }
        # Include any extra context variables
        if hasattr(record, 'file_name'):
            log_record['file_name'] = record.file_name
        if hasattr(record, 'department'):
            log_record['department'] = record.department
        if hasattr(record, 'memory_usage'):
            log_record['memory_usage'] = record.memory_usage
        if hasattr(record, 'cpu_usage'):
            log_record['cpu_usage'] = record.cpu_usage
        if hasattr(record, 'attempt'):
            log_record['attempt'] = record.attempt
        if hasattr(record, 'payload'):
            log_record['payload'] = record.payload
        return json.dumps(log_record)

# Custom Handler with Compression
from logging.handlers import TimedRotatingFileHandler

class GzTimedRotatingFileHandler(TimedRotatingFileHandler):
    def doRollover(self):
        super().doRollover()
        if self.backupCount > 0:
            for s in self.getFilesToDelete():
                if os.path.exists(s):
                    with open(s, 'rb') as f_in, gzip.open(f"{s}.gz", 'wb') as f_out:
                        shutil.copyfileobj(f_in, f_out)
                    os.remove(s)

# Configure logging
logging_config = {
    'version': 1,
    'disable_existing_loggers': False,  # Ensure existing loggers are not disabled
    'formatters': {
        'json': {
            '()': JsonFormatter,
        },
    },
    'handlers': {
        'file': {
            'class': '__main__.GzTimedRotatingFileHandler',
            'formatter': 'json',
            'filename': log_file_path,
            'when': 'midnight',
            'backupCount': max_logs,
        },
        'console': {
            'class': 'logging.StreamHandler',
            'formatter': 'json',
        },
    },
    'root': {
        'level': log_level.upper(),
        'handlers': ['file', 'console'] if log_to_console else ['file'],
    },
    # Configure loggers for third-party modules
    'loggers': {
        '': {
            'level': log_level.upper(),
            'handlers': [],
            'propagate': True,
        },
        'requests': {
            'level': log_level.upper(),
            'handlers': [],
            'propagate': True,
        },
        'urllib3': {
            'level': log_level.upper(),
            'handlers': [],
            'propagate': True,
        },
    },
}

logging.config.dictConfig(logging_config)
logger = logging.getLogger(__name__)

logger.info("Logging initialized.")

# -----------------------------------------------------------------------------
# Error Notification Timestamps for Throttling
# -----------------------------------------------------------------------------
error_notification_timestamps = {}

# -----------------------------------------------------------------------------
# Function: send_pushover_notification
# -----------------------------------------------------------------------------
def send_pushover_notification(message, title="Notification", priority=0, sound=None, error_type=None):
    try:
        cooldown_period = 300  # seconds
        now = time()
        if error_type:
            last_sent = error_notification_timestamps.get(error_type, 0)
            if now - last_sent < cooldown_period:
                logger.info(f"Notification for {error_type} suppressed to avoid overload.")
                return
            else:
                error_notification_timestamps[error_type] = now

        full_title = f"{script_name}: {title}"

        payload = {
            'token': config['Validated']['pushover_token'],
            'user': config['Validated']['pushover_user'],
            'message': message,
            'title': full_title,
            'priority': priority,
            'sound': sound or config['Validated']['sound']
        }

        if priority == 2:
            # Emergency priority requires 'retry' and 'expire' parameters
            payload['retry'] = int(config['Validated']['retry'])
            payload['expire'] = int(config['Validated']['expire'])

        response = requests.post("https://api.pushover.net/1/messages.json", data=payload)
        response.raise_for_status()
        logger.info("Pushover notification sent successfully")
    except Exception as e:
        logger.error("Failed to send Pushover notification", exc_info=True)

# -----------------------------------------------------------------------------
# Function: cleanup_logs
# -----------------------------------------------------------------------------
def cleanup_logs():
    send_pushover_notification("Starting log cleanup.", title="Maintenance", priority=-1)
    now = datetime.now().timestamp()
    logs = []

    # Gather all logs and their ages
    for filename in os.listdir(log_dir):
        file_path = os.path.join(log_dir, filename)
        if os.path.isfile(file_path):
            file_age = now - os.path.getmtime(file_path)
            logs.append((file_path, file_age))

    # Sort logs by age (oldest first)
    logs.sort(key=lambda x: x[1], reverse=False)

    # Get the current log file path to avoid deletion
    current_log_file = log_file_path

    # Archive logs based on age
    archived_files_count = 0
    for file_path, file_age in logs:
        if file_path == current_log_file:
            continue
        if file_age > max_log_days * 86400:
            # Move the file to an archive directory
            archive_dir = os.path.join(log_dir, 'archive')
            os.makedirs(archive_dir, exist_ok=True)
            shutil.move(file_path, archive_dir)
            logger.info(f"Archived old log file: {os.path.basename(file_path)}")
            archived_files_count += 1

    # Re-evaluate logs after age-based cleanup
    logs = [(fp, fa) for fp, fa in logs if os.path.exists(fp)]

    # If number of logs exceeds max_logs, archive the oldest ones
    if len(logs) > max_logs:
        logs_to_archive = len(logs) - max_logs
        for i in range(logs_to_archive):
            if logs[i][0] == current_log_file:
                continue
            archive_dir = os.path.join(log_dir, 'archive')
            os.makedirs(archive_dir, exist_ok=True)
            shutil.move(logs[i][0], archive_dir)
            logger.info(f"Archived excess log file: {os.path.basename(logs[i][0])}")
            archived_files_count += 1

    if archived_files_count == 0:
        logger.info("No old or excess log files were found for archiving.")
    else:
        logger.info(f"Archived {archived_files_count} old or excess log file(s).")

    send_pushover_notification("Log cleanup completed.", title="Maintenance", priority=-1)

# Now that logging is configured, run cleanup
cleanup_logs()

# -----------------------------------------------------------------------------
# Custom Exception Definitions
# -----------------------------------------------------------------------------
class FTPConnectionError(Exception):
    """Raised when FTP connection fails."""
    pass

class FileUploadError(Exception):
    """Raised when file upload fails."""
    pass

class WebhookError(Exception):
    """Raised when webhook sending fails."""
    pass

# -----------------------------------------------------------------------------
# Function: log_and_validate_config
# -----------------------------------------------------------------------------
def log_and_validate_config():
    try:
        logger.info("Starting configuration validation...")

        # FTP settings
        ftp_server = os.getenv('FTP_SERVER') or config['ttd_audio_notification_ftp']['ftp_server']
        ftp_port = os.getenv('FTP_PORT') or config['ttd_audio_notification_ftp']['ftp_port']
        ftp_user = os.getenv('FTP_USER') or config['ttd_audio_notification_ftp']['ftp_user']
        ftp_pass = os.getenv('FTP_PASS') or config['ttd_audio_notification_ftp']['ftp_pass']

        # Logging these values for debugging (avoid sensitive info)
        logger.debug(f"FTP Server: {ftp_server}, FTP Port: {ftp_port}, FTP User: {ftp_user}")

        # Validate FTP settings
        if not ftp_server or not ftp_port or not ftp_user or not ftp_pass:
            raise ValueError("FTP configuration missing or incomplete in .env or config.ini")

        # Base path for audio files
        base_path = config['ttd_audio_notification_Path']['base_path']
        logger.debug(f"Base Path: {base_path}")

        if not base_path:
            raise ValueError("Base path for audio files is missing in config.ini")

        # Pushover settings
        pushover_token = os.getenv('PUSHOVER_TOKEN') or config['ttd_audio_notification_Pushover']['pushover_token']
        pushover_user = os.getenv('PUSHOVER_USER') or config['ttd_audio_notification_Pushover']['pushover_user']
        priority = config['ttd_audio_notification_Pushover'].getint('priority')
        retry = config['ttd_audio_notification_Pushover'].getint('retry')
        expire = config['ttd_audio_notification_Pushover'].getint('expire')
        sound = config['ttd_audio_notification_Pushover']['sound']

        # Log these values
        logger.debug(f"Pushover User: {pushover_user}")

        # Validate Pushover settings
        if not pushover_token or not pushover_user:
            raise ValueError("Pushover configuration missing or incomplete in .env or config.ini")

        # Store validated values in 'Validated' section
        config['Validated'] = {
            'ftp_server': ftp_server,
            'ftp_port': ftp_port,
            'ftp_user': ftp_user,
            'ftp_pass': ftp_pass,
            'base_path': base_path,
            'pushover_token': pushover_token,
            'pushover_user': pushover_user,
            'priority': str(priority),
            'retry': str(retry),
            'expire': str(expire),
            'sound': sound
        }

    except Exception as e:
        logger.error("Configuration validation failed", exc_info=True)
        raise

# -----------------------------------------------------------------------------
# Function: connect_to_ftp
# -----------------------------------------------------------------------------
def connect_to_ftp():
    try:
        logger.debug("Connecting to FTP server")
        ftp = FTP()
        ftp.connect(config['Validated']['ftp_server'], int(config['Validated']['ftp_port']))
        ftp.login(config['Validated']['ftp_user'], config['Validated']['ftp_pass'])
        logger.info("Connected to FTP server", extra={'ftp_server': config['Validated']['ftp_server']})
        return ftp
    except Exception as e:
        logger.error("FTP connection error", exc_info=True)
        raise FTPConnectionError(f"FTP error: {e}")

# -----------------------------------------------------------------------------
# Function: store_file
# -----------------------------------------------------------------------------
def store_file(ftp, local_file, department):
    try:
        file_name = os.path.basename(local_file)
        with open(local_file, 'rb') as f:
            logger.debug("Uploading file", extra={'file_name': file_name})
            ftp.storbinary(f'STOR {file_name}', f)
            logger.info("Uploaded file to FTP server", extra={'file_name': file_name})
            send_webhook(file_name, department)
    except Exception as e:
        logger.error("Failed to upload to FTP server", exc_info=True, extra={'file_name': file_name})
        raise FileUploadError(f"Failed to upload to FTP server: {e}")

# -----------------------------------------------------------------------------
# Function: upload_to_ftp
# -----------------------------------------------------------------------------
def upload_to_ftp(local_file, department):
    """Uploads a file to the FTP server and handles FTP-specific errors."""
    try:
        ftp = connect_to_ftp()
        if ftp:
            try:
                store_file(ftp, local_file, department)
            finally:
                ftp.quit()
                logger.info("FTP connection closed")
                # Send success notification after upload and webhook
                message = f"Successfully processed and uploaded {os.path.basename(local_file)} for {department}."
                send_pushover_notification(message, title="Task Completed", priority=-2, sound='magic')
    except FTPConnectionError as ftp_error:
        message = (
            f"FTPConnectionError at {datetime.now()}: {ftp_error}\n"
            "Possible causes: FTP server down, network issues.\n"
            "Action: Check FTP server status and network connectivity."
        )
        logger.error("FTPConnectionError occurred", exc_info=True)
        send_pushover_notification(message, title="FTP Error", priority=1, sound='siren', error_type='FTPConnectionError')
        raise FileUploadError(f"Failed to upload to FTP server: {ftp_error}")
    except FileUploadError as file_error:
        message = (
            f"FileUploadError at {datetime.now()}: {file_error}\n"
            "Possible causes: File permissions, network issues.\n"
            "Action: Verify file access and network connectivity."
        )
        logger.error("FileUploadError occurred", exc_info=True)
        send_pushover_notification(message, title="File Upload Error", priority=1, sound='alien', error_type='FileUploadError')
        raise file_error

# -----------------------------------------------------------------------------
# Function: run_transcription_script
# -----------------------------------------------------------------------------
def run_transcription_script(mp3_file, department):
    try:
        transcription_script = os.path.join(script_dir, 'ttd_transcribed.py')
        Popen([sys.executable, transcription_script, mp3_file, department])  # Non-blocking call
        logger.info("Started transcription script", extra={'file_name': mp3_file})
    except Exception as e:
        logger.error("Failed to start transcription script", exc_info=True, extra={'file_name': mp3_file})

# -----------------------------------------------------------------------------
# Function: send_webhook
# -----------------------------------------------------------------------------
def send_webhook(file_name, topic, retries=3):
    """Sends a webhook notification to the Node-RED server and handles webhook-specific errors."""
    try:
        if not config.has_section('ttd_audio_notification_Webhook'):
            raise KeyError("Webhook configuration missing")

        file_name = os.path.basename(file_name)
        base_audio_url = config['ttd_audio_notification_Webhook']['base_audio_url']
        file_url = f"{base_audio_url}{file_name}"

        payload = {
            "payload": {
                "message": file_url,
                "title": f"{topic} Audio Uploaded",
                "topic": topic
            }
        }

        attempt = 0
        retry_delay = config['ttd_audio_notification_Retry'].getint('retry_delay')

        timeout_seconds = config['ttd_audio_notification_Webhook'].getint('timeout_seconds')

        while attempt < retries:
            try:
                logger.debug("Sending webhook", extra={'attempt': attempt + 1, 'payload': payload})
                response = requests.post(config['ttd_audio_notification_Webhook']['ttd_audio_received_url'],
                                         json=payload, timeout=timeout_seconds)
                response.raise_for_status()
                logger.info("Webhook sent successfully", extra={'payload': payload})
                return True

            except requests.exceptions.RequestException as e:
                logger.warning("Webhook attempt failed", exc_info=True, extra={'attempt': attempt + 1})
                attempt += 1
                if attempt < retries:
                    logger.info("Retrying webhook", extra={'retry_delay': retry_delay})
                    sleep(retry_delay)

        message = (
            f"WebhookError at {datetime.now()}: Failed after {retries} attempts.\n"
            "Possible causes: Node-RED server down, network issues.\n"
            "Action: Check Node-RED server status and verify the webhook URL."
        )
        logger.error("Webhook failed after all retries")
        send_pushover_notification(message, title="Webhook Error", priority=1, sound='tugboat', error_type='WebhookError')
        raise WebhookError(f"Webhook failed after {retries} attempts.")

    except Exception as e:
        logger.error("Webhook error occurred", exc_info=True)
        raise

# -----------------------------------------------------------------------------
# Function: performance_monitor
# -----------------------------------------------------------------------------
def performance_monitor():
    """Logs CPU and memory usage."""
    memory_usage = psutil.virtual_memory().percent
    cpu_usage = psutil.cpu_percent()
    logger.info("Performance metrics", extra={'memory_usage': memory_usage, 'cpu_usage': cpu_usage})
    # Optionally, send notifications if usage exceeds thresholds
    if memory_usage > 80:
        send_pushover_notification(f"High Memory Usage: {memory_usage}%", title="Resource Alert", priority=1, sound='gamelan', error_type='HighMemoryUsage')
    if cpu_usage > 90:
        send_pushover_notification(f"High CPU Usage: {cpu_usage}%", title="Resource Alert", priority=1, sound='gamelan', error_type='HighCPUUsage')

# -----------------------------------------------------------------------------
# Main Execution
# -----------------------------------------------------------------------------
def main():
    logger.debug("Starting script execution")
    start_time = time()

    try:
        log_and_validate_config()

        if len(sys.argv) != 3:
            raise ValueError(f"Expected 2 arguments (audio file and department), got {len(sys.argv) - 1}")

        mp3_file = os.path.join(config['Validated']['base_path'], sys.argv[1])
        department = sys.argv[2]
        logger.info("Processing file", extra={'file_name': mp3_file, 'department': department})

        # Run the transcription script asynchronously
        run_transcription_script(mp3_file, department)

        # Upload to FTP
        upload_to_ftp(mp3_file, department)

    except Exception as e:
        logger.error("An error occurred in main execution", exc_info=True)
        message = f"An unexpected error occurred at {datetime.now()}: {e}\nAction: Check logs for details."
        send_pushover_notification(message, title="Unexpected Error", priority=1, sound='falling', error_type='UnexpectedError')

    finally:
        execution_time = time() - start_time
        logger.info("Script completed", extra={'execution_time': execution_time})
        performance_monitor()
        logger.debug("Exiting script")

if __name__ == "__main__":
    main()
